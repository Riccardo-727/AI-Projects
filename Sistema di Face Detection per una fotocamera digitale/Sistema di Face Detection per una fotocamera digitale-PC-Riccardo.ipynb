{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistema di Face Detection per una fotocamera digitale\n",
    "\n",
    "La ProCam s.p.a ha intenzione di lanciare sul mercato una nuova fotocamera digitale compatta ed economica destinata a piccoli fotografi in erba.\n",
    "\n",
    "Vieni assunto come Data Scientist per realizzare il sistema di identificazione dei volti nelle immagini, questo permetterà poi ai tecnici della fotografia di ottimizzare le impostazioni per un selfie con una o più persone.\n",
    "\n",
    "Si tratta di un problema di computer vision, più precisamente di Face Detection.\n",
    "\n",
    "Devi fornire una pipeline scikit-learn che prende un'immagine in ingresso e ritorna una lista con le coordinate dei bounding box dove sono presenti dei volti, se nell'immagine non contiene volti la lista sarà ovviamente vuota.\n",
    "\n",
    "\n",
    "NOTA:\n",
    "\n",
    "Non ti viene fornito un dataset, sta a te cercarne uno in rete o, nella peggiore delle ipotesi, costruirlo, per semplicità non considereremo implicazioni sulle licenze ad utilizzo commerciale, si tratta pur sempre di un progetto didattico.\n",
    "Non puoi utilizzare modelli pre-addestrati, devi addestrarlo tu utilizzando scikit-learn.\n",
    "Stai lavorando su un sistema con ridotte capacità di calcolo, quindi il modello deve richiedere poche risorse di calcolo.\n",
    "Ovviamente non ti vengono fornite indicazioni sull'implementazione, fai un'approfondita ricerca bibliografica per trovare la soluzione migliore da adottare, il notebook che consegnerai deve essere ben documentato, devi spiegare quali soluzioni hai adottato e perché ed ogni risorsa esterna (paper, blog post, codice github...) che hai utilizzato.\n",
    "Il progetto è abbastanza complesso, ricorda che in caso ne avessi necessità puoi sempre chiedere aiuto ai tuoi coach nella Classe Virtuale di Machine Learning su Discord.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: yellow; color: black; font-weight: bold;\">sintesi passi per la risoluzione di un problema di object detection:</span>\n",
    "\n",
    "\n",
    "1. Raccolta del Dataset\n",
    "\n",
    "2. Pre-elaborazione delle Immagini\n",
    "\n",
    "* * Le immagini devonio essere prima preprocessate per uniformità e per facilitare l'apprendimento del modello:\n",
    "\n",
    "* * Conversione in Scala di Grigi: I volti possono essere analizzati efficacemente anche senza informazioni sul colore, il che riduce la complessità.\n",
    "* * Ridimensionamento: Uniformare le dimensioni delle immagini per ridurre il carico computazionale e migliorare la velocità di elaborazione.\n",
    "* * Normalizzazione: Normalizzare le intensità dei pixel per migliorare la convergenza durante l'addestramento.\n",
    "\n",
    "3. Estrazione delle Caratteristiche\n",
    "\n",
    "* * Bisogna decidere come estrarre le caratteristiche dalle immagini preprocessate. Alcune tecniche popolari includono:\n",
    "\n",
    "* * Histogram of Oriented Gradients (HOG): Efficace per la rilevazione di oggetti come volti.\n",
    "* * Haar Features: Usato comunemente per la rilevazione di volti, sebbene richieda un addestramento intensivo.\n",
    "* * Reti neurali Convoluzionali: rappresenta l'attuale state of art nell' ambito della computer vision e in particolare nei compiti di object detection. L'addestramento del modello è molto oneroso oltr al fatto che richiede un ingente quantità di dati per essere allenato.\n",
    "\n",
    "4. Addestramento del Modello\n",
    "\n",
    "* * Considerando il requisito di limitate capacità di calcolo:\n",
    "\n",
    "* * * Support Vector Machine (SVM): Può essere addestrato per distinguere tra \"volto\" e \"non volto\" usando le caratteristiche estratte.\n",
    "* * * Adaptive Boosting (AdaBoost): Adatto per migliorare la performance di classificatori deboli e può essere usato per rafforzare la rilevazione di volti.\n",
    "\n",
    "5. Implementazione della Pipeline in scikit-learn:\n",
    "\n",
    "* * Preprocessing: Scala di grigi, ridimensionamento, normalizzazione.\n",
    "* * Estrazione delle caratteristiche: HOG o Haar.\n",
    "* * Classificatore: SVM o AdaBoost.\n",
    "\n",
    "6. Valutazione e Ottimizzazione\n",
    "* * Si valuta il modello con metriche come precision, recall, e F1-score per assicurarti che identifichi accuratamente i volti nelle immagini.\n",
    "* * Tipicamente si utilizza la validazione incrociata e tecniche di ottimizzazione degli iperparametri per migliorare la performance.\n",
    "\n",
    "7. Test su Nuove Immagini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: yellow; color: black; font-weight: bold;\">In particolare per questo progetto sono state fatte le seguenti scelte implementative:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raccolta del dataset\n",
    "\n",
    "Sono stati usati due diversi Dataset, uno contenente volti umani e l'altro contenente immagini di vario tipo, escluse quelle di persone.\n",
    "\n",
    "* Esempi Positivi:\n",
    "\n",
    "E' stato deciso di utilizzare CelebFaces Attributes Dataset (CelebA), un dataset che contiene molte immagini di volti in varie condizioni di illuminazione e pose. \n",
    "\n",
    "In particolare contiene più di 200K immagini di celebrità, ciascuna con 40 annotazioni di attributi. \n",
    "\n",
    "Le caratteristiche chiave sono le seguenti:\n",
    "\n",
    "* * numero di persone considerate: 10.177\n",
    "\n",
    "* * immagini totali: 202.599\n",
    "\n",
    "* * 20 posizioni di riferimento, \n",
    "\n",
    "* * 40 annotazioni di attributi per immagine.\n",
    "\n",
    "Il set di dati può essere utilizzato come set di addestramento e test per le seguenti attività di visione artificiale: riconoscimento degli attributi facciali, riconoscimento facciale, rilevamento dei volti, localizzazione dei punti di riferimento (o parti del viso) e modifica e sintesi dei volti.\n",
    "\n",
    "Scaricabile all'indirizzo: [Labeled Faces in the Wild](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html).\n",
    "\n",
    "\n",
    "* Esempi negativi:\n",
    "\n",
    "[Immagini naturali](https://www.kaggle.com/datasets/prasunroy/natural-images?resource=download)\n",
    "\n",
    "Immagini naturali: un set di dati costituito da 6899 immagini in 8 classi distinte che includono: aereomobili, automobili, gatti, cani, fiori, frutta, moto e persone.\n",
    "In particolare quest'ultima classe è stata rimossa dal dataset prima del suo utilizzo.\n",
    "\n",
    "<span style=\"color: #99CC99; font-weight: bold;\">*Il modello è stato addestrato solo su un sottoinsieme del primo dataset (circa 10000 osservazioni) e ha usato tutto il secondo dataset nel caso degli esempi negativi (circa 5000 osservazioni).*</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione delle Caratteristiche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delle tre tecniche precedentemente esposte quelle effettivamente utilizzabili al fine di rispettare la consegna di questo progetto sono la Histogram of Oriented Gradients (HOG) e la Haar Features.\n",
    "\n",
    "Sebbene tra le due quella più promettente è la HOG in quanto è computazionalmente efficiente con un accuratezza molto alta è stato deciso di usare la Haar Features Cascade in quanto, per svago, si è deciso di implementare l'algoritmo da zero senza l'ausilio di nessuna libreria di *scikit-learn*\n",
    "\n",
    "\n",
    "<span style=\"color: #99CC99; font-weight: bold;\">**Introduzione**</span>\n",
    "\n",
    "\n",
    "I classificatori a cascata di Haar, introdotti da Paul Viola e Michael Jones nel loro articolo del 2001 \"Rapid Object Detection using a Boosted Cascade of Simple Features\", rappresentano una tecnica pionieristica per il rilevamento di oggetti in immagini. Questo metodo è stato utilizzato principalmente per il riconoscimento facciale, ma la sua flessibilità permette di adattarlo a una vasta gamma di oggetti. La tecnica della cascata di Haar sfrutta un insieme di strumenti di apprendimento automatico e di elaborazione delle immagini per identificare oggetti in maniera rapida e precisa, rivoluzionando così il campo del riconoscimento delle immagini.\n",
    "\n",
    "\n",
    "<span style=\"color: #99CC99; font-weight: bold;\">**Concetti Fondamentali**</span>\n",
    "\n",
    "* Caratteristiche Haar-like\n",
    "\n",
    "    Le caratteristiche Haar-like sono il cuore del metodo Haar Cascade. Queste caratteristiche derivano il loro nome da Alfred Haar, un matematico ungherese che ha sviluppato i concetti alla base delle trasformazioni di Haar. Le caratteristiche Haar-like consistono in regioni rettangolari adiacenti in una finestra di rilevamento, in cui viene calcolata la somma dei pixel per valutare le differenze di intensità tra aree chiare e scure. Alcuni esempi di caratteristiche Haar includono:\n",
    "\n",
    "* * Caratteristiche edge: Queste confrontano la luminosità di due rettangoli adiacenti, uno chiaro e uno scuro. Ad esempio, una caratteristica edge verticale potrebbe consistere in un rettangolo chiaro a sinistra e uno scuro a destra. Questa configurazione permette di rilevare bordi verticali all'interno dell'immagine.\n",
    "\n",
    "* * Caratteristiche line: Queste confrontano tre rettangoli adiacenti, dove il rettangolo centrale è scuro e i rettangoli ai lati sono chiari (o viceversa). Questa configurazione è utile per rilevare strutture lineari all'interno dell'immagine.\n",
    "\n",
    "* * Caratteristiche a quattro rettangoli: Queste confrontano l'intensità tra quattro rettangoli disposti a griglia. Questa configurazione è utilizzata per rilevare variazioni più complesse di luminosità.\n",
    "\n",
    "    Le caratteristiche Haar sono molto efficienti da calcolare grazie alla rappresentazione dell'immagine integrale (integral image), che permette di ottenere la somma dei pixel in un rettangolo in tempo costante.\n",
    "\n",
    "* Immagine Integrale\n",
    "\n",
    "    L'immagine integrale è una rappresentazione dell'immagine originale che consente di calcolare rapidamente la somma dei pixel in qualsiasi rettangolo dell'immagine. Questa tecnica, introdotta da Viola e Jones, trasforma l'immagine in modo che ogni pixel dell'immagine integrale rappresenti la somma di tutti i pixel sopra e a sinistra di esso nell'immagine originale. Questo permette di calcolare la somma dei pixel in un rettangolo specifico in tempo costante, indipendentemente dalle dimensioni del rettangolo, rendendo il calcolo delle caratteristiche Haar molto efficiente.\n",
    "\n",
    "* Training con Adaboost\n",
    "\n",
    "    Adaboost (Adaptive Boosting) è una tecnica di machine learning utilizzata per migliorare la precisione dei classificatori. In questo contesto, Adaboost è utilizzato per selezionare le caratteristiche Haar più rilevanti tra migliaia di potenziali caratteristiche. Durante il processo di addestramento, Adaboost combina deboli classificatori per formare un forte classificatore. Un debole classificatore è uno che è solo leggermente migliore di una previsione casuale. Adaboost assegna pesi maggiori agli esempi che sono stati classificati erroneamente, migliorando così la precisione del classificatore finale.\n",
    "\n",
    "    Il processo di Adaboost funziona come segue:\n",
    "\n",
    "* * Inizialmente, tutti gli esempi di training sono pesati equamente.\n",
    "* * Ad ogni iterazione, viene addestrato un debole classificatore sulle caratteristiche Haar.\n",
    "* * Gli esempi che sono stati classificati erroneamente ricevono un peso maggiore.\n",
    "* * Alla fine del processo, i deboli classificatori sono combinati in un forte classificatore ponderando le loro decisioni in base alla loro precisione.\n",
    "\n",
    "* Cascata di Classificatori\n",
    "\n",
    "    La cascata di classificatori è una sequenza di classificatori che vengono applicati sequenzialmente a una finestra di immagine. Ogni classificatore nella cascata filtra le finestre che non contengono l'oggetto di interesse, riducendo così il numero di finestre da analizzare nelle fasi successive. Questo approccio a cascata aumenta significativamente la velocità di rilevamento, poiché le finestre che non passano i primi classificatori vengono scartate rapidamente, evitando di eseguire calcoli più complessi sulle finestre non rilevanti.\n",
    "\n",
    "    La cascata è strutturata in livelli, dove ogni livello contiene un forte classificatore addestrato con Adaboost. I primi livelli contengono classificatori semplici e veloci, mentre i livelli successivi contengono classificatori più complessi. Questo design permette di ottenere un bilancio ottimale tra velocità e accuratezza.\n",
    "\n",
    "* Finestra di Rilevamento\n",
    "\n",
    "    La finestra di rilevamento è un concetto chiave nel metodo Haar Cascade. Si tratta di una finestra di dimensioni fisse che viene fatta scorrere sull'immagine per cercare l'oggetto di interesse. Ogni posizione della finestra viene valutata utilizzando i classificatori a cascata. Le finestre che superano tutti i livelli della cascata sono considerate contenere l'oggetto di interesse.\n",
    "\n",
    "    Per rilevare oggetti di diverse dimensioni, la finestra di rilevamento viene ridimensionata e applicata nuovamente all'immagine. Questo processo è noto come rilevamento multiscala.\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color: #99CC99; font-weight: bold;\">**Bibliografia e Citazioni**</span>\n",
    "\n",
    "Viola, P., & Jones, M. (2001). Rapid object detection using a boosted cascade of simple features. In Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001.\n",
    "\n",
    "[Link: IEEE Xplore](https://ieeexplore.ieee.org/document/990517)\n",
    "\n",
    "Lienhart, R., & Maydt, J. (2002). An extended set of Haar-like features for rapid object detection. In Proceedings. International Conference on Image Processing.\n",
    "\n",
    "[Link: IEEE Xplore](https://ieeexplore.ieee.org/document/1038171)\n",
    "\n",
    "OpenCV Documentation. Haar Feature-based Cascade Classifier for Object Detection.\n",
    "\n",
    "[Link: OpenCV Docs](https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html)\n",
    "\n",
    "Papageorgiou, C., Oren, M., & Poggio, T. (1998). A general framework for object detection. In International Conference on Computer Vision.\n",
    "\n",
    "[Link: MIT AI Lab](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.59.4302&rep=rep1&type=pdf)\n",
    "\n",
    "\n",
    "\n",
    "In particolare la parte **utilities** comprende:\n",
    "\n",
    "* <span style=\"color: #FFCCCC; font-weight: bold;\">**WeakClassifier:**</span> rappresenta un classificatore debole.\n",
    "\n",
    "* <span style=\"color: #FFCCCC; font-weight: bold;\">**Haar:**</span>  rappresenta una Feature Haar.\n",
    "\n",
    "* <span style=\"color: #FFCCCC; font-weight: bold;\">**HetHaarScoreFast:**</span> è una funzione che permette di calcolare il valore di una feature Haar all'interno di una sottofinestra, fa uso delle funzioni <span style=\"color: #FFCCCC; font-weight: bold;\">**subwindow_integral**</span> e <span style=\"color: #FFCCCC; font-weight: bold;\">**blockSum**</span>.\n",
    "\n",
    "* <span style=\"color: #FFCCCC; font-weight: bold;\">**preProcessingImage:**</span> è una funzione che preprocessa l'immagine, le modifice applicate comprendono: conversione in scala di grigi, normalizzazzione di ciascun pizzel nell'intervallo 0-1 e ridimensionamento dell'immagine.\n",
    "\n",
    "* <span style=\"color: #FFCCCC; font-weight: bold;\">**detect_faces:**</span> è una funzione che dato in input una lista di classificatori deboli e un'immagine ritorna le coordinate dei cerchi che racchiudono la superficie dei volti rilevati.\n",
    "\n",
    "* <span style=\"color: #FFCCCC; font-weight: bold;\">**non_max_suppression_circles:**</span> una funzione che riduce il numero di cerchi disegnati in un immagine, in particolare elimina i cerchi la cui area è sovrapposta di una certa quantità (definita dal parametro treshold) rispetto ad altri cerchi aventi importanza maggiore (scores più alta).\n",
    "\n",
    "* Le funzioni rimanenti sono utilities il cui nome è esplicativo della funzione svolta.\n",
    "\n",
    "\n",
    "La parte **Pre-elaboration** comprende:\n",
    "\n",
    "* Una pipeline costituita da due diverse funzionalità:\n",
    "\n",
    "    1. importazione delle immagini e creazione del dataset di Addestramento e Test:\n",
    "    E' stato usato il metodo di validazione Hold-Out in quanto il cross-validation ritenuto troppo oneroso.\n",
    "    La scelta è stata comunque giustificata dalla facilità dell'algoritmo di riconoscere i volti.\n",
    "\n",
    "    2. Creazione delle Features Haar: \n",
    "    sono state definite 6 diversi tipologie di Caratteristiche, per ognuna di queste sono state generate 4 dimensioni diverse rispettivamente di 1, 3, 5 e 7, che a loro volta sono servite per generare una Features con uno start_point diverso in modo tale da coprire tutte le possibili posizioni dell immagine.\n",
    "    Totale features Haar: 6*4*80*80=153600, dove 80*80 è la dimensione in pixel dell immagine.\n",
    "\n",
    "\n",
    "La parte **Training** comprende:\n",
    "\n",
    "* L'algoritmo Haar Cascade che fa uso di adaboost:\n",
    "in particolare questo algoritmo è costituito da due cicli **while** principali:\n",
    "\n",
    "    1. il primo definito da: **while F_i >= F_target**, dove la condizione di arresto coincide col aver trovato una cascata di classificatori che hanno un errore minore o uguale a F_target.\n",
    "    \n",
    "    2. il secondo definito da: **while (TP/nrPos<0.6) and (TN/nrNeg<0.6)**, dove la condizione di arresto coincide col aver trovato un classificatore debole la cui precisione nel calcolare i True Positive e i True Negative sia almeno di 0.6.\n",
    "    In questo ciclo vengono asseganti poi dei pesi ai classificatori deboli che sono sono inversamente proporzionali all'errore commesso da quest ultimo nel rilevare i volti nelle immagini.\n",
    "    Sempre all'interno di questo ciclo vengono definiti dei pesi per ciascuna immagine, direttamente proporzionali all'errore commesso dall algoritmo nel classificarle, intuitivamente si assegna un peso maggiore alle immagini che sono state classsificate erroneamente più volte in modo tale che si possa prestare maggiore attenzione a tali immagini nell'iterazione successiva.\n",
    "    \n",
    "    3. la parte di training è stata eseguita in due trance, causa problemi di memory overflow. In particolare il primo addestramento è stato eseguito prendendo in considerazione, per le osservazioni positive, un dataset comprendente le immagini comprese negli indici: 0-5000 e il secondo le immagini comprese negli indici: 5001-10000.\n",
    "\n",
    "    \n",
    "La parte **Test** comprende:\n",
    "\n",
    "* L'applicazione dell'algoritmo su dati mai visti prima e la relativa stampa delle metriche usate per valutarlo, le principali sono TP, TN, FP, FN, F_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import zipfile\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from training_utils import convertball, showball, training_set_util\n",
    "import dill\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "import seaborn as sns\n",
    "from math import log\n",
    "from math import ceil\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adaboost is use\n",
    "window_size = 80\n",
    "\n",
    "\n",
    "class Haar(object):\n",
    "    def __init__(self, type, feature, size, shape, start):\n",
    "        self.type=type\n",
    "        self.feature = cv2.resize(feature, (shape[1]*size, shape[0]*size), interpolation=cv2.INTER_NEAREST)\n",
    "        self.start = start\n",
    "        self.size=size\n",
    "        self.shape = shape\n",
    "\n",
    "\n",
    "\n",
    "class WeakClassifier(object):\n",
    "    def __init__(self, haar, theta, sign, weight):\n",
    "        self.haar = haar\n",
    "        self.theta = theta\n",
    "        self.sign = sign\n",
    "        self.weight = weight\n",
    "\n",
    "\n",
    "\n",
    "def blockSum(integral, w, h, w_kernel_size, h_kernel_size):\n",
    "    \n",
    "    endw = w + w_kernel_size - 1\n",
    "    endh = h + h_kernel_size - 1\n",
    "\n",
    "    if endh >= integral.shape[0] or endw >= integral.shape[1]:\n",
    "        return 0\n",
    "    \n",
    "    sum = integral[int(endh), int(endw)]\n",
    "\n",
    "    if (w > 0):\n",
    "        sum -= integral[int(endh), int(w - 1)]\n",
    "    if (h > 0):\n",
    "        sum -= integral[int(h - 1), int(endw)]\n",
    "    if (h > 0 and w > 0):\n",
    "        sum += integral[int(h - 1), int(w - 1)]\n",
    "    return sum\n",
    "\n",
    "\n",
    "\n",
    "def subwindow_integral(subwindow):\n",
    "    integral = np.zeros(subwindow.shape)\n",
    "\n",
    "    for r in range(subwindow.shape[0]):\n",
    "        for c in range(subwindow.shape[1]):\n",
    "            greyIntegralVal = subwindow[r,c]\n",
    "\n",
    "            if (r - 1 >= 0 and c - 1 >= 0):\n",
    "                greyIntegralVal -= integral[r-1,c-1]\n",
    "\n",
    "            if (r - 1 >= 0):\n",
    "                greyIntegralVal += integral[r-1,c]\n",
    "\n",
    "            if (c - 1 >= 0):\n",
    "                greyIntegralVal += integral[r,c-1]\n",
    "\n",
    "            integral[r,c]  = greyIntegralVal\n",
    "\n",
    "    return integral\n",
    "\n",
    "\n",
    "\n",
    "def get_haar_score_fast(haar, subwindow, subwindow_integral):\n",
    "\n",
    "    #r = haar.start[0]*haar.size\n",
    "    #c = haar.start[1]*haar.size\n",
    "    r = haar.start[0]\n",
    "    c = haar.start[1]\n",
    "    size_w = haar.feature.shape[1]\n",
    "    size_h = haar.feature.shape[0]\n",
    "\n",
    "    try:\n",
    "\n",
    "        if size_w==2 and size_h==2:\n",
    "            # Simple feature, not using integral\n",
    "            if haar.type==1:\n",
    "                return subwindow[r,c]+subwindow[r+1,c]-subwindow[r,c+1]-subwindow[r+1,c+1]\n",
    "            elif haar.type==2:\n",
    "                return subwindow[r,c]+subwindow[r,c+1]-subwindow[r+1,c]-subwindow[r+1,c+1]\n",
    "            elif haar.type==5:\n",
    "                return subwindow[r,c]+subwindow[r+1,c+1]-subwindow[r,c+1]-subwindow[r+1,c]\n",
    "            elif haar.type==6:\n",
    "                return subwindow[r+1,c]+subwindow[r,c+1]-subwindow[r,c]-subwindow[r+1,c+1]\n",
    "        else:\n",
    "            # More complex features, using integral to reduce array references\n",
    "            if haar.type==1:\n",
    "                return blockSum(subwindow_integral, c, r, size_w / 2, size_h) - blockSum(subwindow_integral, c + (size_w / 2), r, size_w / 2, size_h)\n",
    "            elif haar.type==2:\n",
    "                return blockSum(subwindow_integral, c, r, size_w, size_h / 2) - blockSum(subwindow_integral, c, r + (size_h / 2), size_w, size_h / 2)\n",
    "            elif haar.type==3:\n",
    "                return blockSum(subwindow_integral, c, r, size_w, size_h) - 2 * blockSum(subwindow_integral, c + (size_w / 3), r, size_w / 3, size_h)\n",
    "            elif haar.type==4:\n",
    "                return blockSum(subwindow_integral, c, r, size_w, size_h) - 2 * blockSum(subwindow_integral, c, r + (size_h / 3), size_w, size_h / 3)\n",
    "            elif haar.type==5:\n",
    "                return blockSum(subwindow_integral, c, r, size_w, size_h) - 2 * (blockSum(subwindow_integral, c + (size_w / 2), r ,size_w / 2, size_h / 2) + blockSum(subwindow_integral, c, r + (size_h / 2), size_w / 2, size_h / 2))\n",
    "            elif haar.type==6:\n",
    "                return blockSum(subwindow_integral, c, r, size_w, size_h) - 2 * (blockSum(subwindow_integral, c, r, size_w / 2, size_h / 2) + blockSum(subwindow_integral, c + (size_w / 2), r + (size_h / 2), size_w / 2, size_h / 2))\n",
    "            elif haar.type==7:\n",
    "                if (size_w == 3):\n",
    "                    return blockSum(subwindow_integral, c,r, size_w, size_h) - 2 * subwindow[r + 1, c + 1]\n",
    "                else:\n",
    "                    return blockSum(subwindow_integral, c, r, size_w, size_h) - 2 * blockSum(subwindow_integral, c + (size_w / 3), r + (size_h / 3), size_w / 3, size_h / 3)\n",
    "    \n",
    "    except IndexError:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def feature_weighted_error_rate(actual, predicted, weights):\n",
    "    return sum(weights*(np.not_equal(actual, predicted)))\n",
    "\n",
    "\n",
    "\n",
    "def predict(score, classifier):\n",
    "    if score<classifier.theta:\n",
    "        return -classifier.sign\n",
    "    return classifier.sign\n",
    "\n",
    "\n",
    "\n",
    "def display(fovea):\n",
    "    plt.imshow(fovea, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def preProcessingImage(path, to_grayscale=False, to_normalized=False, to_resize=None):\n",
    "    \n",
    "    if type(path) == str:\n",
    "        img = cv2.imread(path)  \n",
    "    else:\n",
    "        img = path\n",
    "\n",
    "    if to_grayscale == True:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if to_normalized == True:\n",
    "        img = img / 255.0\n",
    "\n",
    "    if to_resize != None:\n",
    "        img = cv2.resize(img, (to_resize, to_resize))\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "def get_positive_samples(path):\n",
    "    positive_samples = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "            img = preProcessingImage(os.path.join(path, file), to_grayscale=True, to_normalized=True, to_resize=window_size)\n",
    "            positive_samples.append(img)\n",
    "\n",
    "    return positive_samples\n",
    "\n",
    "\n",
    "\n",
    "def get_negative_samples(path):\n",
    "    negative_samples = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "            img = preProcessingImage(os.path.join(path, file), to_grayscale=True, to_normalized=True, to_resize=window_size)\n",
    "            negative_samples.append(img)\n",
    "    return negative_samples\n",
    "\n",
    "\n",
    "\n",
    "def detect_faces(original_image, original_classifier, priority_big_scale, no_max_suppression_treshold=0, observation_for_circles=0.7):\n",
    "\n",
    "    classifier = copy.deepcopy(original_classifier) \n",
    "    number_classifier = len(classifier)\n",
    "    image = preProcessingImage(original_image, to_grayscale=True, to_normalized=True, to_resize=window_size)\n",
    "    integral_image = subwindow_integral(image)\n",
    "\n",
    "\n",
    "    circles = []\n",
    "    squares = [1,2,4]\n",
    "\n",
    "    for q in squares:\n",
    "\n",
    "        height = image.shape[0]/q\n",
    "        width = image.shape[1]/q\n",
    "\n",
    "        for y in range(0, int(image.shape[0] - height + 1) , 4):\n",
    "            for x in range(0, int(image.shape[1] - width + 1), 4):\n",
    "\n",
    "                strong_score = 0\n",
    "                sum_weight = 0\n",
    "                points = []\n",
    "                classifier = copy.deepcopy(original_classifier) \n",
    "\n",
    "                for weak_clf in classifier:\n",
    "                         \n",
    "                    new_size = int(weak_clf.haar.size/(q/2)) if q > 1 else weak_clf.haar.size\n",
    "                    new_start = (int(weak_clf.haar.start[0]/q + x),  int(weak_clf.haar.start[1]/q + y))\n",
    "                    weak_clf.haar = Haar(weak_clf.haar.type, weak_clf.haar.feature, weak_clf.haar.size, weak_clf.haar.shape, new_start)\n",
    "\n",
    "                    strong_score += weak_clf.weight * predict(get_haar_score_fast(weak_clf.haar, image, integral_image), weak_clf)\n",
    "                    sum_weight += weak_clf.weight\n",
    "\n",
    "                clas = np.sign(strong_score)\n",
    "\n",
    "                #treshold is a quantity that is comprise from -1 to 1: 1 when all weak classifier return class 1.\n",
    "                treshold = strong_score/sum_weight\n",
    "\n",
    "                if treshold > 0.1:\n",
    "\n",
    "                    for weak_clf in classifier:\n",
    "                        points.append((weak_clf.haar.start[0], weak_clf.haar.start[1]))\n",
    "    \n",
    "                    center, radius = compute_simple_circle(points, threshold_ratio=observation_for_circles)\n",
    "                    circles.append((int(center[0]), int(center[1]), int(radius), q^(-1) if priority_big_scale == True else q^(2) ))\n",
    "\n",
    "    return non_max_suppression_circles(circles, no_max_suppression_treshold)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def circle_intersection_area(c1, r1, c2, r2):\n",
    "    # Calcola la distanza Euclidea tra i centri dei cerchi\n",
    "    d = np.linalg.norm(np.array(c1) - np.array(c2))\n",
    "\n",
    "    # Caso in cui i cerchi non si sovrappongono\n",
    "    if d >= r1 + r2:\n",
    "        return 0.0\n",
    "\n",
    "    # Caso in cui un cerchio è completamente contenuto nell'altro\n",
    "    if d <= abs(r1 - r2):\n",
    "        return np.pi * min(r1, r2) ** 2\n",
    "\n",
    "    # Calcola l'area di intersezione tra i cerchi\n",
    "    a = r1 ** 2\n",
    "    b = r2 ** 2\n",
    "    x = (a - b + d ** 2) / (2 * d)\n",
    "    z = x ** 2\n",
    "    y = np.sqrt(a - z)\n",
    "    \n",
    "    # Calcola l'area di intersezione utilizzando la formula della sezione circolare\n",
    "    if d < r1 - r2 or d < r2 - r1:\n",
    "        return np.pi * min(r1, r2) ** 2\n",
    "    else:\n",
    "        return a * np.arcsin(y / r1) + b * np.arcsin(y / r2) - y * (x + np.sqrt(z + b - a))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def circle_iou(c1, r1, c2, r2):\n",
    "    inter_area = circle_intersection_area(c1, r1, c2, r2)\n",
    "    union_area = np.pi * (r1 ** 2) + np.pi * (r2 ** 2) - inter_area\n",
    "    return inter_area / union_area\n",
    "\n",
    "\n",
    "\n",
    "def non_max_suppression_circles(circles, overlapThresh):\n",
    "    \n",
    "    if len(circles) == 0:\n",
    "        return [(0, 0, 1, 0)]\n",
    "\n",
    "    if len(circles) == 1:\n",
    "        circle = circles[0]\n",
    "        return [(circle[0], circle[1], circle[2], circle[3])]\n",
    "\n",
    "    circles = np.array(circles)\n",
    "    \n",
    "    if circles.dtype.kind == \"i\":\n",
    "        circles = circles.astype(\"float\")\n",
    "\n",
    "    pick = []\n",
    "    x = circles[:, 0]\n",
    "    y = circles[:, 1]\n",
    "    r = circles[:, 2]\n",
    "    scores = circles[:, 3]\n",
    "\n",
    "    idxs = np.argsort(scores)\n",
    "\n",
    "    while len(idxs) > 0:\n",
    "        \n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        suppress = [last]\n",
    "\n",
    "        for pos in range(last):\n",
    "            \n",
    "            j = idxs[pos]\n",
    "            iou = circle_iou((x[i], y[i]), r[i], (x[j], y[j]), r[j])\n",
    "            \n",
    "            if iou > overlapThresh:\n",
    "                suppress.append(pos)\n",
    "\n",
    "        idxs = np.delete(idxs, suppress)\n",
    "\n",
    "    selected_circles = circles[pick].astype(\"int\")\n",
    "\n",
    "    result = [(circle[0], circle[1], circle[2], circle[3]) for circle in selected_circles]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# non_max_suppression for rectangle\n",
    "def non_max_suppression_rectangle(boxes, overlapThresh):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # Converti i bounding box in un array NumPy, se necessario\n",
    "    boxes = np.array(boxes)\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    pick = []\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    score = boxes[:, 4]\n",
    "\n",
    "    # Calcola l'area di ciascun bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    # Ordina gli indici dei bounding box per punteggio (in ordine crescente)\n",
    "    idxs = np.argsort(score)\n",
    "\n",
    "    while len(idxs) > 0:\n",
    "        # Prendi l'indice dell'elemento con il punteggio più alto\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # Trova le coordinate delle intersezioni\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        # Calcola larghezza e altezza dell'intersezione\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        # Calcola l'area dell'intersezione e il rapporto di sovrapposizione (IoU)\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        # Elimina gli elementi che hanno un rapporto di sovrapposizione superiore alla soglia\n",
    "        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "    # Restituisci i bounding box selezionati\n",
    "    return boxes[pick].astype(\"int\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_circle(points, threshold_distance_percent=0.7):\n",
    "\n",
    "\n",
    "    # Find the \"elbow\" in the elbow method graph\n",
    "    def find_elbow_point(K, ssd):\n",
    "        \n",
    "        # Coordinates of the points\n",
    "        points_elbow = np.array(list(zip(K, ssd)))\n",
    "        \n",
    "        # Initial point (first point)\n",
    "        p1 = points_elbow[0]\n",
    "        # Final point (last point)\n",
    "        p2 = points_elbow[-1]\n",
    "        \n",
    "        # Distances of each point from the line segment p1-p2\n",
    "        distances = []\n",
    "        for point in points_elbow:\n",
    "            distances.append(np.abs(np.cross(p2-p1, p1-point) / np.linalg.norm(p2-p1)))\n",
    "        \n",
    "        # Find the index with the maximum distance\n",
    "        elbow_index = np.argmax(distances)\n",
    "        return K[elbow_index]\n",
    "\n",
    "\n",
    "\n",
    "    #first use k-means algorithm to detect the number of possible face\n",
    "    list_points = [point[0] for point in points]\n",
    "    coordinates = np.array(list_points)\n",
    "\n",
    "    K = range(1, 5)  \n",
    "    ssd = []\n",
    "\n",
    "    for k in K:\n",
    "        kmeans = KMeans(init=\"k-means++\", n_clusters=k, random_state=0).fit(coordinates)\n",
    "        ssd.append(kmeans.inertia_)\n",
    "\n",
    "    # Get the optimal number of clusters\n",
    "    optimal_k = find_elbow_point(K, ssd)\n",
    "\n",
    "    kmeans_final = KMeans(init=\"k-means++\", n_clusters=optimal_k, random_state=0).fit(coordinates)\n",
    "    ssd_final = kmeans_final.inertia_\n",
    "\n",
    "    # Get cluster centers\n",
    "    cluster_centers = kmeans_final.cluster_centers_\n",
    "\n",
    "    # Get the points belonging to each cluster\n",
    "    labels = kmeans_final.labels_\n",
    "\n",
    "\n",
    "\n",
    "    def plot_clusters(model, data, axlabels=None, print_ssd=False):\n",
    "        y_pred = model.predict(data)\n",
    "        sns.scatterplot(x=data[:,0], y=data[:,1], hue=y_pred, s=100)\n",
    "        plt.scatter(model.cluster_centers_[:, 0], model.cluster_centers_[:, 1], c='red', s=200, alpha=0.5)\n",
    "\n",
    "        if axlabels!=None:\n",
    "            plt.xlabel(axlabels[0], fontsize=16)\n",
    "            plt.ylabel(axlabels[1], fontsize=16)\n",
    "\n",
    "        if print_ssd:\n",
    "            plt.text(X[:,0].max()-10, 0, f\"SSD={model.inertia_:.2f}\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    plot_clusters(kmeans_final, coordinates, None, False)\n",
    "\n",
    "\n",
    "    # Group points by cluster\n",
    "    clusters = {}\n",
    "    for i in range(optimal_k):\n",
    "        clusters[i] = [points[j] for j in range(len(points)) if labels[j] == i]\n",
    "\n",
    "    circles = []\n",
    "\n",
    "    # Calculate circle for each cluster using the centroid as the center\n",
    "    for cluster_id, cluster_points in clusters.items():\n",
    "        \n",
    "        cluster_coordinates = np.array([p[0] for p in cluster_points])\n",
    "        scores = np.array([p[1] for p in cluster_points])\n",
    "        \n",
    "        # Use the centroid of the cluster as the center\n",
    "        center_x, center_y = cluster_centers[cluster_id]\n",
    "        \n",
    "        # Calculate the distances from the center to each point\n",
    "        distances = np.sqrt((cluster_coordinates[:, 0] - center_x)**2 + (cluster_coordinates[:, 1] - center_y)**2)\n",
    "        \n",
    "        # Determine the threshold distance to include the closest threshold% of points\n",
    "        threshold_distance = np.percentile(distances, threshold_distance_percent * 100)\n",
    "        \n",
    "        # Select the points within the threshold distance\n",
    "        close_points = cluster_coordinates[distances <= threshold_distance]\n",
    "        close_scores = scores[distances <= threshold_distance]\n",
    "        \n",
    "        # Calculate the radius as the maximum distance from the center to any selected point\n",
    "        radius = np.max(np.sqrt((close_points[:, 0] - center_x)**2 + (close_points[:, 1] - center_y)**2))\n",
    "        \n",
    "        # Calculate the score as the sum of the scores of the close points\n",
    "        total_score = np.sum(close_scores)\n",
    "        \n",
    "        # Append the circle (x, y, radius, score) to the list\n",
    "        circles.append((int(center_x), int(center_y), int(radius), total_score))\n",
    "    \n",
    "    return circles\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_simple_circle(points, threshold_ratio=0.5):\n",
    "\n",
    "    # Convert the list of points to a NumPy array for easier manipulation\n",
    "    points = np.array(points)\n",
    "    \n",
    "    # Calculate the initial center of the circle as the mean of the coordinates\n",
    "    center_x = np.mean(points[:, 0])\n",
    "    center_y = np.mean(points[:, 1])\n",
    "    center = (center_x, center_y)\n",
    "    \n",
    "    # Calculate the distances from the initial center to each point\n",
    "    distances = np.sqrt((points[:, 0] - center_x)**2 + (points[:, 1] - center_y)**2)\n",
    "    \n",
    "    # Determine the threshold distance\n",
    "    threshold_distance = threshold_ratio * np.max(distances)\n",
    "    \n",
    "    # Filter points within the threshold distance from the initial center\n",
    "    filtered_points = points[distances <= threshold_distance]\n",
    "    \n",
    "    if len(filtered_points) < 2:\n",
    "        raise ValueError(\"Not enough points to form a circle after applying the threshold.\")\n",
    "    \n",
    "    # Recalculate the center of the circle using the filtered points\n",
    "    center_x = np.mean(filtered_points[:, 0])\n",
    "    center_y = np.mean(filtered_points[:, 1])\n",
    "    center = (center_x, center_y)\n",
    "    \n",
    "    # Recalculate the radius as the maximum distance from the new center to any filtered point\n",
    "    distances = np.sqrt((filtered_points[:, 0] - center_x)**2 + (filtered_points[:, 1] - center_y)**2)\n",
    "    radius = np.max(distances)\n",
    "    \n",
    "    return center, radius\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_circle(points, center, radius):\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Plot the points\n",
    "    points = np.array(points)\n",
    "    ax.scatter(points[:, 0], points[:, 1], label='Points')\n",
    "    \n",
    "    # Plot the circle\n",
    "    circle = plt.Circle(center, radius, color='b', fill=False, label='Bounding Circle')\n",
    "    ax.add_artist(circle)\n",
    "    \n",
    "    # Plot the center\n",
    "    ax.plot(center[0], center[1], 'ro', label='Center')\n",
    "    \n",
    "    ax.set_aspect('equal', 'box')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Points and Bounding Circle')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Function to write in a file the coordinates of the image given in the path\n",
    "def draw_rectangle(images_path, output_file):\n",
    "    # Load the Haar Cascade model for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # Open the output file\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Write the file header\n",
    "        f.write(\"image_id x_1 y_1 width height\\n\")\n",
    "        \n",
    "        # Iterate through all images in the specified directory\n",
    "        for image_name in os.listdir(images_path):\n",
    "            \n",
    "            # Construct the full path of the image\n",
    "            image_path = os.path.join(images_path, image_name)\n",
    "            \n",
    "            # Load the image\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Error loading image: {image_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Convert the image to grayscale\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Detect faces in the image\n",
    "            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "            \n",
    "            # For each detected face, save the rectangle coordinates and dimensions\n",
    "            for (x, y, w, h) in faces:\n",
    "                f.write(f\"{image_name} {x} {y} {w} {h}\\n\")\n",
    "                \n",
    "                # Draw the rectangle on the image (optional, for visualization only)\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                \n",
    "                # Show the image with the rectangle (optional, for debugging only)\n",
    "                # cv2.imshow(\"Image with Rectangle\", image)\n",
    "                # cv2.waitKey(0)\n",
    "                # cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "# Function to draw a rectangle on the image with coordinates given\n",
    "def draw_rectangle(image_path, x1, y1, x2, y2):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Check if the image was loaded correctly\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Rectangle color (BGR)\n",
    "    color = (0, 255, 0)  # Green\n",
    "    thickness = 2  # Rectangle thickness\n",
    "\n",
    "    # Draw the rectangle on the image\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "    # Convert the image from BGR to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Show the image with the rectangle drawn\n",
    "    cv2.imshow(\"Image with Rectangle\", image_rgb)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#Function to draw a rectangle on the image with OpenCV\n",
    "def draw_rectangle(image_path):\n",
    "    # Load the Haar Cascade model for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,    # Reduce the image by 10% at each scale\n",
    "        minNeighbors=3,     # Require at least 3 neighboring rectangles to confirm a face\n",
    "        minSize=(20, 20)    # Minimum size of the detection rectangle\n",
    "    )\n",
    "\n",
    "    # Check if faces have been detected\n",
    "    if len(faces) == 0:\n",
    "        print(\"No faces detected\")\n",
    "        return\n",
    "\n",
    "    # For each detected face, draw the rectangle on the image\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Show the image with all the rectangles drawn\n",
    "    cv2.imshow(\"Image with Rectangle\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-elaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Build Training and Test Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of samples at our disposal:\n",
      "Positives: 5000\n",
      "Negatives: 5864\n",
      "For training\n",
      "Positives: 4750\n",
      "Negatives: 5570\n",
      "For testing\n",
      "Positives: 250\n",
      "Negatives: 294\n"
     ]
    }
   ],
   "source": [
    "# creation file Boundary.txt\n",
    "#images_path = 'Dataset\\\\Osservazioni positive ridotte'\n",
    "#output_file = 'Dataset\\\\Boundary.txt'\n",
    "\n",
    "# Call the function to draw the rectangle\n",
    "#draw_rectangle(images_path, output_file)\n",
    "\n",
    "\n",
    "# Generate positive samples\n",
    "positive_samples = get_positive_samples(\"Dataset\\\\Osservazioni positive 0-5000\")\n",
    "#positive_samples = get_positive_samples(\"Dataset\\\\Osservazioni positive 5001-10000\")\n",
    "#positive_samples_rotated = [np.rot90(np.rot90(np.rot90(el))) for el in positive_samples]\n",
    "#positive_samples = positive_samples + positive_samples_rotated\n",
    "\n",
    "# Generate Negative samples\n",
    "negative_samples = get_negative_samples(\"Dataset\\\\Osservazioni negative\")\n",
    "#negative_samples_rotated = [np.rot90(np.rot90(np.rot90(el))) for el in negative_samples]\n",
    "#negative_samples = negative_samples + negative_samples_rotated\n",
    "\n",
    "# Shuffle all the samples\n",
    "np.random.shuffle(positive_samples)\n",
    "np.random.shuffle(negative_samples)\n",
    "\n",
    "print(\"Total num of samples at our disposal:\")\n",
    "print(\"Positives: \" + str(len(positive_samples)))\n",
    "print(\"Negatives: \" + str(len(negative_samples)))\n",
    "\n",
    "split = 0.95\n",
    "pos_split = int(len(positive_samples)*split)\n",
    "neg_split = int(len(negative_samples)*split)\n",
    "\n",
    "training_set = positive_samples[0:pos_split] + negative_samples[0:neg_split]\n",
    "testing_set = positive_samples[pos_split:] + negative_samples[neg_split:]\n",
    "\n",
    "training_integrals = [subwindow_integral(el) for el in training_set]\n",
    "testing_integrals = [subwindow_integral(el) for el in testing_set]\n",
    "\n",
    "nrPos = pos_split\n",
    "nrNeg = neg_split\n",
    "\n",
    "nrPos_test = len(positive_samples)-nrPos\n",
    "nrNeg_test = len(negative_samples)-nrNeg\n",
    "\n",
    "training_labels = [1]*nrPos + [-1]*nrNeg\n",
    "testing_labels = [1]*nrPos_test + [-1]*nrNeg_test\n",
    "\n",
    "print(\"For training\")\n",
    "print(\"Positives: \"+str(nrPos))\n",
    "print(\"Negatives: \"+str(nrNeg))\n",
    "\n",
    "print(\"For testing\")\n",
    "print(\"Positives: \"+str(nrPos_test))\n",
    "print(\"Negatives: \"+str(nrNeg_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Build Haar Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108708\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define haar feature types\n",
    "haar1 = np.array([1, -1,\n",
    "                  1, -1])\n",
    "haar1.shape = (2,2)\n",
    "\n",
    "haar2 = np.array([1, 1,\n",
    "                  -1, -1])\n",
    "haar2.shape = (2,2)\n",
    "\n",
    "haar3 = np.array([1, -1, 1,\n",
    "                  1, -1, 1])\n",
    "haar3.shape = (2,3)\n",
    "\n",
    "haar4 = np.array([1, 1,\n",
    "                  -1, -1,\n",
    "                  1, 1])\n",
    "haar4.shape = (3,2)\n",
    "\n",
    "haar5 = np.array([1, -1,\n",
    "                  -1, 1])\n",
    "haar5.shape = (2,2)\n",
    "\n",
    "haar6 = np.array([-1, 1,\n",
    "                  1, -1])\n",
    "haar6.shape = (2,2)\n",
    "\n",
    "\n",
    "\n",
    "# lista di caratteristiche haar, per ogni tipo vengono considerate size diverse. (start positions semrpe uguale a zero)\n",
    "features_start=[]\n",
    "\n",
    "\n",
    "# Define many sizes for all feature types\n",
    "haar_feature_types=[haar1,haar2,haar3,haar4,haar5,haar6]\n",
    "for f in range(len(haar_feature_types)):\n",
    "    \n",
    "    shape = haar_feature_types[f].shape\n",
    "    \n",
    "    if 3 in haar_feature_types[f].shape:\n",
    "        max_size=4\n",
    "    else:\n",
    "        max_size=7\n",
    "\n",
    "    for s in range(1, max_size+1, 2):\n",
    "        features_start.append(Haar(f+1, haar_feature_types[f], s, shape, (0,0)))\n",
    "\n",
    "\n",
    "# contiene tutte le caratteristiche haar usate per l algoritmo (per ogni tipo e per ogni size tutte le start positions possibili)\n",
    "features = []\n",
    "for j in features_start:\n",
    "        \n",
    "        # Get all posible starting locations for this feature\n",
    "        starting_positions = []\n",
    "        space = (window_size-j.shape[0]*j.size, window_size-j.shape[1]*j.size)\n",
    "        \n",
    "        for k in range(space[0]+1):\n",
    "            for l in range(space[1]+1):\n",
    "                starting_positions.append((k, l))\n",
    "\n",
    "        for loc in starting_positions:\n",
    "            features.append(Haar(j.type, j.feature, j.size, j.shape, loc))\n",
    "\n",
    "\n",
    "#for f in features:\n",
    "#    print(f.feature)\n",
    "#    print(f.start)\n",
    "\n",
    "features = list(features)\n",
    "n1 = len(set(features))\n",
    "n2 = len(features)\n",
    "print(n1)\n",
    "\n",
    "feature_weights=[]\n",
    "weak_classifires = []\n",
    "\n",
    "\n",
    "np.random.shuffle(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.8907368421052632 0.9023339317773789 0.09766606822262118 0.10926315789473684\n",
      "Threshold of the best feature (best_weak_classifier.theta): -2.1600241462958865\n",
      "108708\n",
      "[[ 1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1]\n",
      " [-1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1]]\n",
      "F_i: 0.10346461305867902\n",
      "Cascade size: 1\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.8077894736842105 0.8174147217235188 0.18258527827648116 0.19221052631578947\n",
      "Threshold of the best feature (best_weak_classifier.theta): 4.574697586098466\n",
      "108708\n",
      "[[ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
      "F_i: 0.10346461305867902\n",
      "Cascade size: 2\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.868 0.7982046678635547 0.20179533213644524 0.132\n",
      "Threshold of the best feature (best_weak_classifier.theta): -3.218269459752864\n",
      "108708\n",
      "[[ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]]\n",
      "F_i: 0.0817698195218747\n",
      "Cascade size: 3\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.7012631578947368 0.8859964093357271 0.11400359066427289 0.29873684210526313\n",
      "Threshold of the best feature (best_weak_classifier.theta): -0.15127639567506637\n",
      "108708\n",
      "[[ 1  1]\n",
      " [-1 -1]]\n",
      "F_i: 0.07537560238117735\n",
      "Cascade size: 4\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.8985263157894737 0.3635547576301616 0.6364452423698385 0.10147368421052631\n",
      "Threshold of the best feature (best_weak_classifier.theta): 0.016147549085525865\n",
      "108708\n",
      "[[ 1  1]\n",
      " [-1 -1]]\n",
      "F_i: 0.07528999338561844\n",
      "Cascade size: 5\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.8090526315789474 0.7895870736086176 0.2104129263913824 0.19094736842105264\n",
      "Threshold of the best feature (best_weak_classifier.theta): -3.0082963592365313\n",
      "108708\n",
      "[[ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
      "F_i: 0.06681016724936219\n",
      "Cascade size: 6\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.7456842105263158 0.8457809694793537 0.1542190305206463 0.2543157894736842\n",
      "Threshold of the best feature (best_weak_classifier.theta): -9.62079641092151\n",
      "108708\n",
      "[[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
      "F_i: 0.06341831238779175\n",
      "Cascade size: 7\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.696 0.7003590664272891 0.29964093357271093 0.304\n",
      "Threshold of the best feature (best_weak_classifier.theta): -0.9401528642095706\n",
      "108708\n",
      "[[ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
      "F_i: 0.05776566191061136\n",
      "Cascade size: 8\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.8233684210526315 0.37001795332136445 0.6299820466786356 0.17663157894736842\n",
      "Threshold of the best feature (best_weak_classifier.theta): 0.0011727623529249641\n",
      "108708\n",
      "[[ 1 -1]\n",
      " [-1  1]]\n",
      "F_i: 0.05892298970046301\n",
      "Cascade size: 9\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.7298947368421053 0.7531418312387792 0.24685816876122083 0.27010526315789474\n",
      "Threshold of the best feature (best_weak_classifier.theta): -0.6120247756238318\n",
      "108708\n",
      "[[ 1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1]\n",
      " [-1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1]]\n",
      "F_i: 0.05500689785505056\n",
      "Cascade size: 10\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.6477894736842106 0.8883303411131059 0.11166965888689408 0.3522105263157895\n",
      "Threshold of the best feature (best_weak_classifier.theta): 0.13588430158696502\n",
      "108708\n",
      "[[ 1  1]\n",
      " [-1 -1]]\n",
      "F_i: 0.050088443730511197\n",
      "Cascade size: 11\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.6684210526315789 0.4788150807899461 0.5211849192100538 0.33157894736842103\n",
      "Threshold of the best feature (best_weak_classifier.theta): 0.07131329750450449\n",
      "108708\n",
      "[[ 1  1  1 -1 -1 -1]\n",
      " [ 1  1  1 -1 -1 -1]\n",
      " [ 1  1  1 -1 -1 -1]\n",
      " [-1 -1 -1  1  1  1]\n",
      " [-1 -1 -1  1  1  1]\n",
      " [-1 -1 -1  1  1  1]]\n",
      "F_i: 0.04663346877066994\n",
      "Cascade size: 12\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.6391578947368421 0.7689407540394974 0.2310592459605027 0.3608421052631579\n",
      "Threshold of the best feature (best_weak_classifier.theta): 1.0161043169442852\n",
      "108708\n",
      "[[ 1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1]\n",
      " [-1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1]]\n",
      "F_i: 0.043909477463857136\n",
      "Cascade size: 13\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.7938947368421052 0.4421903052064632 0.5578096947935368 0.20610526315789474\n",
      "Threshold of the best feature (best_weak_classifier.theta): -6.618597789323535e-05\n",
      "108708\n",
      "[[-1  1]\n",
      " [ 1 -1]]\n",
      "F_i: 0.04267995842388737\n",
      "Cascade size: 14\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.6305263157894737 0.8224416517055655 0.17755834829443448 0.36947368421052634\n",
      "Threshold of the best feature (best_weak_classifier.theta): -0.06710213332787324\n",
      "108708\n",
      "[[ 1  1]\n",
      " [-1 -1]]\n",
      "F_i: 0.04080128507984503\n",
      "Cascade size: 15\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.8292631578947368 0.38617594254937165 0.6138240574506284 0.17073684210526316\n",
      "Threshold of the best feature (best_weak_classifier.theta): -0.0003778210603089898\n",
      "108708\n",
      "[[-1  1]\n",
      " [ 1 -1]]\n",
      "F_i: 0.04027761504299348\n",
      "Cascade size: 16\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.664 0.8719928186714542 0.12800718132854577 0.336\n",
      "Threshold of the best feature (best_weak_classifier.theta): -0.11822988309060405\n",
      "108708\n",
      "[[ 1  1]\n",
      " [-1 -1]]\n",
      "F_i: 0.037860342058017575\n",
      "Cascade size: 17\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.696 0.610592459605027 0.38940754039497305 0.304\n",
      "Threshold of the best feature (best_weak_classifier.theta): 0.7402059550510692\n",
      "108708\n",
      "[[ 1  1]\n",
      " [-1 -1]\n",
      " [ 1  1]]\n",
      "F_i: 0.03887555513559482\n",
      "Cascade size: 18\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.6172631578947368 0.48491921005385996 0.51508078994614 0.38273684210526315\n",
      "Threshold of the best feature (best_weak_classifier.theta): 0.6204138205263517\n",
      "108708\n",
      "[[ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
      "F_i: 0.03846678635547576\n",
      "Cascade size: 19\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.6789473684210526 0.7937163375224416 0.20628366247755836 0.32105263157894737\n",
      "Threshold of the best feature (best_weak_classifier.theta): -2.7722570399532946\n",
      "108708\n",
      "[[ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]]\n",
      "F_i: 0.036284607389209106\n",
      "Cascade size: 20\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.7242105263157895 0.785637342908438 0.21436265709156194 0.27578947368421053\n",
      "Threshold of the best feature (best_weak_classifier.theta): 0.9608781754267272\n",
      "108708\n",
      "[[ 1  1  1 -1 -1 -1]\n",
      " [ 1  1  1 -1 -1 -1]\n",
      " [ 1  1  1 -1 -1 -1]\n",
      " [ 1  1  1 -1 -1 -1]\n",
      " [ 1  1  1 -1 -1 -1]\n",
      " [ 1  1  1 -1 -1 -1]]\n",
      "F_i: 0.03435623169233677\n",
      "Cascade size: 21\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.8054736842105263 0.3046678635547576 0.6953321364452424 0.19452631578947369\n",
      "Threshold of the best feature (best_weak_classifier.theta): -0.03158510021291787\n",
      "108708\n",
      "[[ 1 -1]\n",
      " [ 1 -1]]\n",
      "F_i: 0.03396560521591231\n",
      "Cascade size: 22\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.5128421052631579 0.7499102333931777 0.25008976660682225 0.4871578947368421\n",
      "Threshold of the best feature (best_weak_classifier.theta): 6.624926483706075\n",
      "108708\n",
      "[[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
      "F_i: 0.032114712274402345\n",
      "Cascade size: 23\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.8153684210526316 0.43895870736086173 0.5610412926391383 0.18463157894736842\n",
      "Threshold of the best feature (best_weak_classifier.theta): -8.947759039539224e-05\n",
      "108708\n",
      "[[-1  1]\n",
      " [ 1 -1]]\n",
      "F_i: 0.03212057072663706\n",
      "Cascade size: 24\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.608 0.8542190305206463 0.14578096947935368 0.392\n",
      "Threshold of the best feature (best_weak_classifier.theta): 0.10171450241065337\n",
      "108708\n",
      "[[ 1  1]\n",
      " [-1 -1]]\n",
      "F_i: 0.03037494094302183\n",
      "Cascade size: 25\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.8050526315789474 0.42692998204667865 0.5730700179533214 0.19494736842105262\n",
      "Threshold of the best feature (best_weak_classifier.theta): -0.000760914322973118\n",
      "108708\n",
      "[[-1  1]\n",
      " [ 1 -1]]\n",
      "F_i: 0.02967816309175092\n",
      "Cascade size: 26\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.880421052631579 0.8416517055655296 0.15834829443447038 0.11957894736842105\n",
      "Threshold of the best feature (best_weak_classifier.theta): -4.398638137742894\n",
      "108708\n",
      "[[ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1  1  1  1  1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
      "F_i: 0.0291085703486724\n",
      "Cascade size: 27\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.7174736842105263 0.41346499102333933 0.5865350089766607 0.2825263157894737\n",
      "Threshold of the best feature (best_weak_classifier.theta): 0.013433966308167634\n",
      "108708\n",
      "[[ 1 -1]\n",
      " [ 1 -1]]\n",
      "F_i: 0.027213833506567135\n",
      "Cascade size: 28\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.6309473684210526 0.8156193895870736 0.1843806104129264 0.36905263157894735\n",
      "Threshold of the best feature (best_weak_classifier.theta): -0.06532810652335821\n",
      "108708\n",
      "[[ 1  1]\n",
      " [-1 -1]]\n",
      "F_i: 0.026833412075970897\n",
      "Cascade size: 29\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.623578947368421 0.6563734290843806 0.3436265709156194 0.37642105263157893\n",
      "Threshold of the best feature (best_weak_classifier.theta): -0.7068966696870813\n",
      "108708\n",
      "[[-1 -1 -1 -1 -1  1  1  1  1  1]\n",
      " [-1 -1 -1 -1 -1  1  1  1  1  1]\n",
      " [-1 -1 -1 -1 -1  1  1  1  1  1]\n",
      " [-1 -1 -1 -1 -1  1  1  1  1  1]\n",
      " [-1 -1 -1 -1 -1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1 -1 -1 -1 -1 -1]]\n",
      "F_i: 0.02612756307285269\n",
      "Cascade size: 30\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.6696842105263158 0.3755834829443447 0.6244165170556553 0.33031578947368423\n",
      "Threshold of the best feature (best_weak_classifier.theta): -0.06622504123219017\n",
      "108708\n",
      "[[-1 -1 -1  1  1  1]\n",
      " [-1 -1 -1  1  1  1]\n",
      " [-1 -1 -1  1  1  1]\n",
      " [ 1  1  1 -1 -1 -1]\n",
      " [ 1  1  1 -1 -1 -1]\n",
      " [ 1  1  1 -1 -1 -1]]\n",
      "F_i: 0.02532873476329963\n",
      "Cascade size: 31\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.604 0.6759425493716338 0.3240574506283663 0.396\n",
      "Threshold of the best feature (best_weak_classifier.theta): -0.2287137754269793\n",
      "108708\n",
      "[[ 1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1  1]\n",
      " [-1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1]]\n",
      "F_i: 0.02534101861475952\n",
      "Cascade size: 32\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.6208421052631579 0.6585278276481149 0.3414721723518851 0.3791578947368421\n",
      "Threshold of the best feature (best_weak_classifier.theta): 3.2776135889327382\n",
      "108708\n",
      "[[ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]]\n",
      "F_i: 0.025031654540300482\n",
      "Cascade size: 33\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.791578947368421 0.4378815080789946 0.5621184919210054 0.20842105263157895\n",
      "Threshold of the best feature (best_weak_classifier.theta): 0.0007529003202451515\n",
      "108708\n",
      "[[-1  1]\n",
      " [ 1 -1]]\n",
      "F_i: 0.025087215345365208\n",
      "Cascade size: 34\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.6629473684210526 0.8666068222621185 0.1333931777378815 0.3370526315789474\n",
      "Threshold of the best feature (best_weak_classifier.theta): -0.11992679424076948\n",
      "108708\n",
      "[[ 1  1]\n",
      " [-1 -1]]\n",
      "F_i: 0.023743928942643863\n",
      "Cascade size: 35\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.6585263157894737 0.4535008976660682 0.5464991023339317 0.3414736842105263\n",
      "Threshold of the best feature (best_weak_classifier.theta): 0.0010139873347099443\n",
      "108708\n",
      "[[-1  1]\n",
      " [ 1 -1]]\n",
      "F_i: 0.02350240952470944\n",
      "Cascade size: 36\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.5795789473684211 0.6910233393177738 0.30897666068222623 0.420421052631579\n",
      "Threshold of the best feature (best_weak_classifier.theta): -1.1977453992598812\n",
      "108708\n",
      "[[ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1]]\n",
      "F_i: 0.02257375035434187\n",
      "Cascade size: 37\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.5322105263157895 0.5175942549371634 0.4824057450628366 0.46778947368421053\n",
      "Threshold of the best feature (best_weak_classifier.theta): 0.0021847217959794474\n",
      " \n",
      "TP, TN, FP, FN for the current weak classifier:\n",
      "0.5322105263157895 0.5175942549371634 0.4824057450628366 0.46778947368421053\n",
      "Threshold of the best feature (best_weak_classifier.theta): 0.0021847217959794474\n",
      " \n"
     ]
    }
   ],
   "source": [
    "cascade = []\n",
    "errors = []\n",
    "scores = []\n",
    "thetas = []\n",
    "polarities = []\n",
    "\n",
    "# For every feature, find best threshold and compute corresponding weighted error\n",
    "for j in features:\n",
    "    avgPosScore = 0.0\n",
    "    avgNegScore = 0.0\n",
    "\n",
    "    # Apply feature to each image and get threshold for current feature (current location)\n",
    "    for i in range(len(training_set)):\n",
    "        score=get_haar_score_fast(j, training_set[i], training_integrals[i])\n",
    "        scores.append(score)\n",
    "\n",
    "        if training_labels[i]==1:\n",
    "            avgPosScore += score\n",
    "        else:\n",
    "            avgNegScore += score\n",
    "\n",
    "    avgPosScore = avgPosScore / nrPos\n",
    "    avgNegScore = avgNegScore / nrNeg\n",
    "\n",
    "    #note: dataset must be bilanced, otherwis avgPosScore couuld be major of avgNegScore only because the numbero of the positivi image is > of negative image and vice versa\n",
    "    if avgPosScore>avgNegScore:\n",
    "        polarity = 1\n",
    "    else:\n",
    "        polarity = -1\n",
    "\n",
    "    polarities.append(polarity)\n",
    "\n",
    "    # Optimal theta found\n",
    "    theta = (avgPosScore + avgNegScore) / 2\n",
    "    thetas.append(theta)\n",
    "\n",
    "\n",
    "### Cascade Creation ###\n",
    "\n",
    "#0.001\n",
    "F_target = 0.01\n",
    "f = 0.5\n",
    "\n",
    "F_i = 1\n",
    "#i = 0\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "image_weights = [1.0/(2*nrPos)]*nrPos + [1.0/(2*nrNeg)]*nrNeg\n",
    "\n",
    "show_stuff = False\n",
    "\n",
    "while F_i >= F_target:\n",
    "    #i += 1\n",
    "    ## Train classifier for stage i\n",
    "\n",
    "    #best_feature_index = 0\n",
    "    best_weak_classifier = 0\n",
    "    lowest_error = float(\"inf\")\n",
    "\n",
    "    #image_weights = [1.0/(2*nrNeg)]*nrNeg + [1.0/(2*nrPos)]*nrPos\n",
    "    total = sum(image_weights)\n",
    "    image_weights = [w / total for w in image_weights]\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "\n",
    "    f_i = 1\n",
    "    cycle = 0\n",
    "\n",
    "    #while f_i > f: # change condition TP>0.5 and TN>0.5 ?!\n",
    "    while (TP/nrPos<0.6) and (TN/nrNeg<0.6):\n",
    "        \n",
    "        total = sum(image_weights)\n",
    "        \n",
    "        if total != 1:\n",
    "            image_weights = [w / total for w in image_weights]\n",
    "\n",
    "        print(\" \")\n",
    "        errors = []\n",
    "        # For every feature, find best threshold and compute corresponding weighted error\n",
    "        loop_cnt = 0\n",
    "        inner_loop_cnt = 0\n",
    "\n",
    "        for j in features:\n",
    "\n",
    "            # Create classifier object\n",
    "            w_classif = WeakClassifier(j, thetas[loop_cnt], polarities[loop_cnt], 0)\n",
    "\n",
    "            # Compute weighted error\n",
    "            predicted = []\n",
    "            for sample in range(len(training_set)):\n",
    "                # Get predictions of all samples\n",
    "                score=scores[inner_loop_cnt]\n",
    "                predicted.append(predict(score, w_classif))\n",
    "                inner_loop_cnt += 1\n",
    "\n",
    "            weighted_error=feature_weighted_error_rate(training_labels, predicted, image_weights)\n",
    "            errors.append(weighted_error)\n",
    "\n",
    "            # Look for the lowest error and keep track of the corresponding classifier\n",
    "            if weighted_error<lowest_error:\n",
    "                lowest_error = weighted_error\n",
    "                best_weak_classifier = w_classif\n",
    "                #best_feature_index = features.index(j)\n",
    "\n",
    "            loop_cnt+=1\n",
    "            \n",
    "        if best_weak_classifier == 0:\n",
    "            continue\n",
    " \n",
    "        #print(\"Best feature index: \"+str(best_feature_index))\n",
    "\n",
    "        if show_stuff:\n",
    "            plt.plot(errors)\n",
    "            plt.show()\n",
    "\n",
    "        ## Choose weak classifier with lowest error ##\n",
    "        beta_t = lowest_error/(1-lowest_error)\n",
    "\n",
    "        if beta_t == 0:\n",
    "            inverted_weighth = 0\n",
    "        else:\n",
    "            inverted_weighth = log(1/beta_t)\n",
    "\n",
    "        best_weak_classifier.weight = inverted_weighth\n",
    "\n",
    "        ## Update weights and evaluate current weak classifier ##\n",
    "        predicted=[]\n",
    "        scores_debug = []\n",
    "\n",
    "        for sample in range(len(training_set)):\n",
    "\n",
    "            # Get weighted classification error\n",
    "            score=get_haar_score_fast(best_weak_classifier.haar, training_set[sample], training_integrals[sample])\n",
    "            scores_debug.append(score)\n",
    "            predicted.append(predict(score, best_weak_classifier))\n",
    "\n",
    "        FP = 0.0\n",
    "        FN = 0.0\n",
    "        TP = 0.0\n",
    "        TN = 0.0\n",
    "\n",
    "        colors_predicted = []\n",
    "\n",
    "        for k in range(len(image_weights)):\n",
    "           \n",
    "            # if sample is not correctly classified\n",
    "            if training_labels[k] == 1 and predicted[k] == -1:\n",
    "                FN += 1\n",
    "            if training_labels[k] == -1 and predicted[k] == 1:\n",
    "                FP += 1\n",
    "\n",
    "            # Update image weights\n",
    "            if training_labels[k] == predicted[k]:\n",
    "                image_weights[k] = image_weights[k]*beta_t\n",
    "\n",
    "                if predicted[k] == 1:\n",
    "                    TP += 1\n",
    "                if predicted[k] == -1:\n",
    "                    TN += 1\n",
    "\n",
    "            if predicted[k] == -1:\n",
    "                colors_predicted.append('r')\n",
    "            else:\n",
    "                colors_predicted.append('g')\n",
    "\n",
    "        ## Evaluate f_i\n",
    "        #f_i = (FP/(2*nrNeg))+(FN/(2*nrPos))\n",
    "        #print(\"f_i: \" + str(f_i))\n",
    "\n",
    "        print(\"TP, TN, FP, FN for the current weak classifier:\")\n",
    "        print(TP/nrPos, TN/nrNeg, FP/nrNeg, FN/nrPos)\n",
    "\n",
    "        ## Visualize the performace of weak classifier for training samples\n",
    "        if show_stuff:\n",
    "            plt.scatter(range(nrPos+nrNeg), scores_debug, c = colors_predicted)\n",
    "            plt.vlines(nrPos,min(scores_debug),max(scores_debug))\n",
    "            plt.plot(range(nrPos+nrNeg), [best_weak_classifier.theta]*(nrPos+nrNeg))\n",
    "            plt.xlim(0,nrPos+nrNeg)\n",
    "            plt.show()\n",
    "\n",
    "        print(\"Threshold of the best feature (best_weak_classifier.theta): \"+str(best_weak_classifier.theta))\n",
    "\n",
    "        #cycle += 1\n",
    "\n",
    "    cascade.append(best_weak_classifier)\n",
    "\n",
    "    print(len(features))\n",
    "\n",
    "    print(best_weak_classifier.haar.feature)\n",
    "\n",
    "    strong_FP = 0.0\n",
    "    strong_FN = 0.0\n",
    "\n",
    "    cascade_scores = []\n",
    "    cascade_colors_predicted = []\n",
    "\n",
    "    for l in range(len(training_set)):\n",
    "        \n",
    "        strong_score = 0.0\n",
    "        \n",
    "        for w_class in cascade:\n",
    "            strong_score += w_class.weight * predict(get_haar_score_fast(w_class.haar, training_set[l], training_integrals[l]), w_class)\n",
    "        \n",
    "        cascade_scores.append(strong_score)\n",
    "        clas = np.sign(strong_score)\n",
    "        \n",
    "        if clas==-1:\n",
    "            cascade_colors_predicted.append('r')\n",
    "        else:\n",
    "            cascade_colors_predicted.append('g')\n",
    "\n",
    "        if training_labels[l] == 1 and clas == -1:\n",
    "            strong_FN += 1\n",
    "        \n",
    "        if training_labels[l] == -1 and clas == 1:\n",
    "            strong_FP += 1\n",
    "\n",
    "    ## Visualize the performace of the cascade on training samples\n",
    "    if show_stuff:\n",
    "        plt.scatter(range(nrPos+nrNeg), cascade_scores, c = cascade_colors_predicted)\n",
    "        plt.vlines(nrPos,min(cascade_scores),max(cascade_scores))\n",
    "        plt.plot(range(nrPos+nrNeg), [0]*(nrPos+nrNeg))\n",
    "        plt.xlim(0,nrPos+nrNeg)\n",
    "        plt.show()\n",
    "\n",
    "    F_i = (strong_FP/(2*nrNeg))+(strong_FN/(2*nrPos))\n",
    "    print(\"F_i: \" + str(F_i))\n",
    "    print(\"Cascade size: \"+str(len(cascade)))\n",
    "    \n",
    "    #cascade variable save\n",
    "    #nome_file = \"cascade_2.pkl\"\n",
    "    #file = open(nome_file, 'wb')\n",
    "    #pickle.dump(cascade, file)\n",
    "    #file.close()\n",
    "\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running cascade on the testing set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x265c3fef910>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x265c3f82810>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x265c5025750>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x265c3f86e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP, TN, FP, FN for the cascade classifier:\n",
      "0.976 0.9897959183673469 0.01020408163265306 0.024\n"
     ]
    }
   ],
   "source": [
    "with open('cascade_1.pkl', 'rb') as file:\n",
    "    cascade_1 = pickle.load(file)\n",
    "\n",
    "with open('cascade_2.pkl', 'rb') as file:\n",
    "    cascade_2 = pickle.load(file)\n",
    "\n",
    "cascade = cascade_1 + cascade_2\n",
    "\n",
    "print(\"Now running cascade on the testing set\")\n",
    "\n",
    "FP_test = 0.0\n",
    "FN_test = 0.0\n",
    "TP_test = 0.0\n",
    "TN_test = 0.0\n",
    "\n",
    "scores = []\n",
    "\n",
    "with open('final_cascade.txt', 'w') as file_cascade:\n",
    "\n",
    "    file_cascade.write(\"CASCADE: \\n\")\n",
    "    f_cnt=1\n",
    "\n",
    "    for el in cascade:\n",
    "        \n",
    "        file_cascade.writelines(\"Best Classifier in Cascade: \\n\")\n",
    "        file_cascade.writelines(f\"#{str(f_cnt):}: \\n\")\n",
    "        file_cascade.writelines(f\"Best_Classfier.haar.type: {el.haar.type}\\n\")\n",
    "        file_cascade.writelines(f\"Best_Classfier.haar.size: {el.haar.size}\\n\")\n",
    "        file_cascade.writelines(f\"Best_Classfier.haar.feature.shape: {el.haar.feature.shape}\\n\")\n",
    "        file_cascade.writelines(f\"Best_Classfier.haar.shape: {el.haar.shape}\\n\")\n",
    "        file_cascade.writelines(f\"Best_Classfier.haar.start: {el.haar.start}\\n\")\n",
    "        file_cascade.writelines(f\"Best_Classfier.theta: {str(el.theta)}\\n\")\n",
    "        file_cascade.writelines(f\"Best_Classfier.sign: {str(el.sign)}\\n\")\n",
    "        file_cascade.writelines(f\"Best_Classfier.weight: {str(el.weight)}\\n\\n\")\n",
    "\n",
    "        f_cnt+=1\n",
    "\n",
    "save = False\n",
    "\n",
    "for t in range(len(testing_set)):\n",
    "    strong_score = 0.0\n",
    "    for w_class in cascade:\n",
    "        #print(\"Loc: \" +str(w_class.haar.start))\n",
    "        strong_score += w_class.weight * predict(get_haar_score_fast(w_class.haar, testing_set[t], testing_integrals[t]), w_class)\n",
    "    clas = np.sign(strong_score)\n",
    "    scores.append(strong_score)\n",
    "\n",
    "    if testing_labels[t] == 1 and clas == -1:\n",
    "        FN_test += 1\n",
    "        if save:\n",
    "            plt.imshow(testing_set[t], interpolation='nearest')\n",
    "            plt.savefig(\"FN/\"+str(t)+\".jpg\")\n",
    "    if testing_labels[t] == -1 and clas == 1:\n",
    "        FP_test += 1\n",
    "        if save:\n",
    "            plt.imshow(testing_set[t], interpolation='nearest')\n",
    "            plt.savefig(\"FP/\"+str(t)+\".jpg\")\n",
    "    if testing_labels[t] == 1 and clas == 1:\n",
    "        TP_test += 1\n",
    "        if save:\n",
    "            plt.imshow(testing_set[t], interpolation='nearest')\n",
    "            plt.savefig(\"TP/\"+str(t)+\".jpg\")\n",
    "    if testing_labels[t] == -1 and clas == -1:\n",
    "        TN_test += 1\n",
    "        if save:\n",
    "            plt.imshow(testing_set[t], interpolation='nearest')\n",
    "            plt.savefig(\"TN/\"+str(t)+\".jpg\")\n",
    "\n",
    "    #print(testing_labels[t]==clas)\n",
    "    #print(testing_labels[t])\n",
    "    #print(clas)\n",
    "\n",
    "\n",
    "#print(FP_test/(2*nrNeg_test))+(FN_test/(2*nrPos_test))\n",
    "#print(FP_test)\n",
    "#print(FN_test)\n",
    "\n",
    "plt.plot(range(nrPos_test), scores[0:nrPos_test], \"go\", label=\"Score for positive Observation\")\n",
    "plt.plot(range(nrPos_test,nrPos_test+nrNeg_test), scores[nrPos_test:], \"ro\", label=\"Score for negative Observation\")\n",
    "plt.plot(range(nrNeg_test), [0]*nrNeg_test)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"TP, TN, FP, FN for the cascade classifier:\")\n",
    "print(TP_test/nrPos_test, TN_test/nrNeg_test, FP_test/nrNeg_test, FN_test/nrPos_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_circle(image, original_size, priority_big_scale, no_max_suppression_treshold, observation_for_circle):\n",
    "\n",
    "    result = detect_faces(image, cascade, priority_big_scale, no_max_suppression_treshold, observation_for_circle)\n",
    "    image = cv2.resize(image, (original_size, original_size))\n",
    "\n",
    "\n",
    "    if result == None:\n",
    "        cv2.imshow('Detected Faces', image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        return\n",
    "\n",
    "\n",
    "    for r in range(0, len(result)):\n",
    "        center = (int(result[r][0] * original_size / window_size), int(result[r][1] * original_size / window_size)) \n",
    "        radius = int(result[r][2]* original_size / window_size)\n",
    "        cv2.circle(image, center, radius, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    cv2.imshow('Detected Faces', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Detect circle su immagini con solo una persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param observation_for_circle =1\n",
    "\n",
    "image = cv2.imread('Dataset\\\\Person\\\\person_2.jpg')\n",
    "detect_circle(image, 180, True, 0.0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param observation_for_circle = 0.5\n",
    "\n",
    "image = cv2.imread('Dataset\\\\Person\\\\person_2.jpg')\n",
    "detect_circle(image, 180, True, 0.0, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param observation_for_circle = 0.5\n",
    "\n",
    "image = cv2.imread('Dataset\\\\Person\\\\person_4.jpg')\n",
    "detect_circle(image, 180, True, 0.0, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param observation_for_circle = 0.5\n",
    "\n",
    "image = cv2.imread('Dataset\\\\Person\\\\person_6.jpg')\n",
    "detect_circle(image, 180, True, 0.0, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param observation_for_circle = 0.5\n",
    "\n",
    "image = cv2.imread('Dataset\\\\Person\\\\person_7.jpg')\n",
    "detect_circle(image, 180, True, 0.0, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param no_max_suppression_treshold = 0\n",
    "#param observation_for_circle = 0.5\n",
    "#param priority_big_scale = False\n",
    "\n",
    "image = cv2.imread('Dataset\\\\Person\\\\person_7.jpg')\n",
    "detect_circle(image, 180, False, 0.0, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param no_max_suppression_treshold = 1\n",
    "#param observation_for_circle = 0.5\n",
    "#param priority_big_scale = False\n",
    "\n",
    "image = cv2.imread('Dataset\\\\Person\\\\person_7.jpg')\n",
    "detect_circle(image, 180, False, 1, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come si vede dagli esempi precedenti il parametro priority_big_scale se impostato a True darà un peso maggiore ai cerchi trovati su una scala di immagine maggiori se su False farà il contrario.\n",
    "\n",
    "Questo servirà alla funzione non_max_suppression per eliminare i cerchi che si sovrappongono nell'immagine tenendo conto della loro importanza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Detect circle su immagini di gruppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param priority_big_scale = True\n",
    "#param no_max_suppression_treshold = 0\n",
    "#param observation_for_circle = 1\n",
    "\n",
    "image = cv2.imread('Dataset\\\\Varie\\\\oscar.jpg')\n",
    "detect_circle(image, 300, True, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param priority_big_scale = False\n",
    "#param no_max_suppression_treshold = 0\n",
    "#param observation_for_circle = 1\n",
    "\n",
    "image = cv2.imread('Dataset\\\\Varie\\\\oscar.jpg')\n",
    "detect_circle(image, 300, False, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param priority_big_scale = False\n",
    "#param no_max_suppression_treshold = 0\n",
    "#param observation_for_circle = 0.65\n",
    "\n",
    "image = cv2.imread('Dataset\\\\Varie\\\\oscar.jpg')\n",
    "detect_circle(image, 300, False, 0, 0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param priority_big_scale = False\n",
    "#param no_max_suppression_treshold = 0.1\n",
    "#param observation_for_circle = 0.65\n",
    "\n",
    "image = cv2.imread('Dataset\\\\Varie\\\\oscar.jpg')\n",
    "detect_circle(image, 300, False, 0.1, 0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo progetto è stato portato un sistema di face detection che ha raggiunto i seguenti risultati:\n",
    "\n",
    "\n",
    "* Ottime capacità di rilevare se in un'immagine ci sono volti: 0.976% (TP)\n",
    "* Ottime capacità di rilevare se in un'immagine non ci sono volti: 0.989% (FP)\n",
    "* Ottime capacità nel definire un cerchio che contiene il volto di una persona nel caso di immagini con persone singole.\n",
    "* Sufficienti capacità nel definire un cerchio che contiene il volto di una persona nel caso di immagini con più persone.\n",
    "\n",
    "Implementazioni future:\n",
    "\n",
    "* Migliorare le capacità dell'algoritmo di disegnare cerchi nel caso di immagini con più persone, alcuni suggerimenti potrebbero essere:\n",
    "    1. Allenare l'algoritmo usando piu Osservazioni\n",
    "    2. Migliorare la funzione detect_faces, la quale contiene una logica abbastanza basica per il disegno dei cerchi.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
